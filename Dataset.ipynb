{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894be918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import uuid\n",
    "from uuid import uuid4\n",
    "# data manipulation\n",
    "import pandas as pd \n",
    "import string\n",
    "# normalize nested JSON files\n",
    "from pandas.io.json import json_normalize\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2, urllib.request , nltk , textract\n",
    "from io import BytesIO\n",
    "import json\n",
    "#import weasyprint\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "from fuzzywuzzy import fuzz\n",
    "import json\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import regex\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('stopwords')  \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"OKU-fact-sheets-out.json\"\n",
    "with open(json_file_path, 'r') as json_file: \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca7c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the contents from OKU json\n",
    "links = [x['link'] for x in data]\n",
    "texts = [x['content'] for x in data]\n",
    "displaydate = [x['displaydate'] for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e2f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the data into dataframe\n",
    "df1 = pd.DataFrame(links)\n",
    "df1.columns = ['extension_links']\n",
    "df2 = pd.DataFrame(texts)\n",
    "df_new=df2.copy()\n",
    "df_new['text'] = df_new[df_new.columns[0:110]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "df_new = df_new.drop(df_new.columns[0:111],axis=1)\n",
    "df3 = pd.DataFrame(displaydate)\n",
    "df3.columns = ['Displaydate']\n",
    "all_data = pd.concat([df1,df_new,df3],axis=1, join='inner')\n",
    "all_data['row_num'] = np.arange(len(all_data))\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create unique id based on date,OKU, and the unique number of document\n",
    "all_data['unique_id'] = all_data['Displaydate'].astype(str)+'-'+all_data['row_num'].astype(str)+'-'+'OKU'\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877923b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it to csv format\n",
    "all_data.to_csv(\"all_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173fe75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make each row to separate json file\n",
    "df = pd.read_csv('all_data.csv', header=0, dtype=str) \n",
    "df['unique_id'] = df['unique_id'].map(str)\n",
    "df.set_index('unique_id', inplace=True)\n",
    "for unique_id, data in df.iterrows():\n",
    "    data.to_csv(rf'C:\\Users\\Xiangyu Ren\\Documents\\NASS project\\{unique_id}.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
